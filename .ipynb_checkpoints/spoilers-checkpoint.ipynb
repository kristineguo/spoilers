{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spoilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Kristine Guo and Caroline Ho\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "0. [Overview](#Overview)\n",
    "0. [Set-up](#Set-up)\n",
    "0. [Baseline](#Baseline)\n",
    "  0. [Features](#Features)\n",
    "  0. [Experiment](#Experiment)\n",
    "0. [Sentiment](#Sentiment)\n",
    "0. [Dependency Parsing](#Dependency-Parsing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set-up\n",
    "\n",
    "* Download [the TV Tropes dataset](http://cs.colorado.edu/~jbg/downloads/spoilers.tar.gz), unpack it, and place it in the current directory (or wherever you point `data_home` to below).\n",
    "\n",
    "* Download [PorterStemmer](https://tartarus.org/martin/PorterStemmer/python.txt) and save as a .py file in the current directory.\n",
    "\n",
    "* Download [the Stanford parser](https://nlp.stanford.edu/software/stanford-parser-full-2018-02-27.zip), unpack it, and place it in the current directory.\n",
    "\n",
    "* Download [English models for the Stanford parser](https://nlp.stanford.edu/software/stanford-english-corenlp-2018-02-27-models.jar), unpack the file, and place it in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import copy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import PorterStemmer\n",
    "import scipy.stats\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import LinearSVC\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = 'tvtropes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = pd.read_csv(\n",
    "    os.path.join(data_home, 'dev1.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2 = pd.read_csv(\n",
    "    os.path.join(data_home, 'dev2.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    os.path.join(data_home, 'test.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    os.path.join(data_home, 'train.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.loc[0, 'trope'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer.PorterStemmer()\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def parse_sentence(sentence):\n",
    "    s = sentence.translate(translator).split()\n",
    "    for i in range(len(s)):\n",
    "        s[i] = s[i].strip(string.punctuation).lower()\n",
    "    s = list(filter(None, s))\n",
    "    return [word for word in s if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features\n",
    "\n",
    "Description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unigrams_phi(s):\n",
    "    return Counter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_phi(s):\n",
    "    return Counter([ps.stem(word) for word in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_phi(s):\n",
    "    t = copy.deepcopy(s)\n",
    "    t.insert(0, '<S>')\n",
    "    t.append('</S>')\n",
    "    bigrams = [tuple([t[i], t[i + 1]]) for i in range(len(t) - 1)]\n",
    "    return Counter(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiment\n",
    "\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_X(X, phi, vectorizer=None, should_parse=True):\n",
    "    feat_dicts = []\n",
    "    if should_parse: feat_dicts = [phi(parse_sentence(sentence)) for sentence in X]\n",
    "    else:\n",
    "        phi(X)\n",
    "        file = open(\"train_parsed.txt\", \"rb\")\n",
    "        while True:\n",
    "            try:\n",
    "                feat_dicts.append(pickle.load(file))\n",
    "            except EOFError:\n",
    "                break\n",
    "        file.close()\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=False)\n",
    "        return (vectorizer.fit_transform(feat_dicts), vectorizer)\n",
    "    else:\n",
    "        return (vectorizer.transform(feat_dicts), vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, phi, vectorizer=None, should_parse=True):\n",
    "    X = [data.loc[i, 'sentence'] for i in range(len(data.index))]\n",
    "    y = [data.loc[i, 'spoiler'] for i in range(len(data.index))]\n",
    "    feat_matrix, vectorizer = vectorize_X(X, phi, vectorizer=vectorizer, should_parse=should_parse)\n",
    "    return (normalize(feat_matrix), y, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc(X, y):\n",
    "    mod = LinearSVC()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(phi, train_func, train_data, test_data, should_parse=True):\n",
    "    X, y, vectorizer = build_dataset(train_data, phi, should_parse=should_parse)\n",
    "    print(len(X[0]))\n",
    "    mod = train_func(X, y)\n",
    "    X_test, y_test, vectorizer = build_dataset(test_data, phi, vectorizer=vectorizer, should_parse=should_parse)\n",
    "    predictions = mod.predict(X_test)\n",
    "    print('Accuracy: %0.03f' % accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions, digits=3))\n",
    "    return f1_score(y_test, predictions, average = 'macro', pos_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(unigrams_phi, fit_svc, train, dev1)\n",
    "experiment(stemmed_phi, fit_svc, train, dev1)\n",
    "experiment(bigrams_phi, fit_svc, train, dev1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_phi(s):\n",
    "    t = copy.deepcopy(s)\n",
    "    is_neg = 0\n",
    "    for i in range(len(t)):\n",
    "        if is_neg > 4: is_neg = 0\n",
    "        if is_neg > 0:\n",
    "            is_neg += 1\n",
    "            t[i] = 'NOT_' + t[i]\n",
    "        if 'n\\'t' in t[i] or t[i] in ['not', 'no', 'never']: is_neg = 1\n",
    "    return Counter(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment(sentiment_phi, fit_svc, train, dev1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_jar = 'stanford-parser-full-2018-02-27/stanford-parser.jar'\n",
    "path_to_models_jar = 'stanford-english-corenlp-2018-02-27-models.jar'\n",
    "\n",
    "dep_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [list(parse.triples()) for parse in dep_parser.raw_parse(\"The quick brown fox jumps over the lazy dog.\")]\n",
    "print(x, len(x))\n",
    "y = [[list(parse.triples()) for parse in dep_graphs] for dep_graphs in dep_parser.raw_parse_sents([\"The quick brown fox jumps over the lazy dog.\", \"I like rice.\"])]\n",
    "print(y, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_phi(sentence):\n",
    "    deps = []\n",
    "    for parse in dep_parser.raw_parse(sentence):\n",
    "        for t in parse.triples():\n",
    "            deps.append(t[2][0] + '-' + t[0][0])\n",
    "    return Counter(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_mass_phi(sentences):\n",
    "    feat_dicts = []\n",
    "    for dep_graphs in dep_parser.raw_parse_sents(sentences):\n",
    "        deps = []\n",
    "        for parse in dep_graphs:\n",
    "            for t in parse.triples():\n",
    "                deps.append(t[2][0] + '-' + t[0][0])\n",
    "        feat_dicts.append(Counter(deps))\n",
    "    return feat_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_mass_pickle_phi(sentences):\n",
    "    file = open(\"train_parsed.txt\", \"wb\")\n",
    "    for dep_graphs in dep_parser.raw_parse_sents(sentences):\n",
    "        deps = []\n",
    "        for parse in dep_graphs:\n",
    "            for t in parse.triples():\n",
    "                deps.append(t[2][0] + '-' + t[0][0])\n",
    "        output = pickle.dump(Counter(deps), file)\n",
    "    file.close()\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(dep_mass_pickle_phi, fit_svc, train, dev1, should_parse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(dep_phi, fit_svc, train, dev1, should_parse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, phi, vectorizer=None, lda=None):\n",
    "    X = [data.loc[i, 'sentence'] for i in range(len(data.index))]\n",
    "    y = [data.loc[i, 'spoiler'] for i in range(len(data.index))]\n",
    "    feat_matrix, vectorizer = vectorize_X(X, phi, vectorizer)\n",
    "    if lda==None:\n",
    "        lda = LatentDirichletAllocation(n_components=50)\n",
    "        feat_matrix = lda.fit_transform(feat_matrix)\n",
    "    else:\n",
    "        feat_matrix = lda.transform(feat_matrix)\n",
    "    return (normalize(feat_matrix), y, vectorizer, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(phi, train_func, train_data, test_data):\n",
    "    X, y, vectorizer, lda = build_dataset(train_data, phi)\n",
    "    print(len(X[0]))\n",
    "    mod = train_func(X, y)\n",
    "    X_test, y_test, vectorizer, lda = build_dataset(test_data, phi, vectorizer=vectorizer, lda=lda)\n",
    "    predictions = mod.predict(X_test)\n",
    "    print('Accuracy: %0.03f' % accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions, digits=3))\n",
    "    return f1_score(y_test, predictions, average = 'macro', pos_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(unigrams_phi, fit_svc, train, dev1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
