{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Spoilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Kristine Guo and Caroline Ho\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2018 term\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contents\n",
    "\n",
    "0. [Overview](#Overview)\n",
    "0. [Set-up](#Set-up)\n",
    "0. [Latent Semantic Analysis](#Latent-Semantic-Analysis)\n",
    "  0. [Overview of the LSA method](#Overview-of-the-LSA-method)\n",
    "  0. [Motivating example for LSA](#Motivating-example-for-LSA)\n",
    "  0. [Applying LSA to real VSMs](#Applying-LSA-to-real-VSMs)\n",
    "  0. [Other resources for matrix factorization](#Other-resources-for-matrix-factorization)\n",
    "0. [GloVe](#GloVe)\n",
    "  0. [Overview of the GloVe method](#Overview-of-the-GloVe-method)\n",
    "  0. [GloVe implementation notes](#GloVe-implementation-notes)\n",
    "  0. [Applying GloVe to our motivating example](#Applying-GloVe-to-our-motivating-example)\n",
    "  0. [Testing the GloVe implementation](#Testing-the-GloVe-implementation)\n",
    "  0. [Applying GloVe to real VSMs](#Applying-GloVe-to-real-VSMs)\n",
    "0. [Autoencoders](#Autoencoders)\n",
    "  0. [Overview of the autoencoder method](#Overview-of-the-autoencoder-method)\n",
    "  0. [Testing the autoencoder implementation](#Testing-the-autoencoder-implementation)\n",
    "  0. [Applying autoencoders to real VSMs](#Applying-autoencoders-to-real-VSMs)\n",
    "0. [word2vec](#word2vec)\n",
    "  0. [Training data](#Training-data)\n",
    "  0. [Basic skip-gram](#Basic-skip-gram)\n",
    "  0. [Skip-gram with noise contrastive estimation ](#Skip-gram-with-noise-contrastive-estimation-)\n",
    "  0. [word2vec resources](#word2vec-resources)\n",
    "0. [Other methods](#Other-methods)\n",
    "0. [Exploratory exercises](#Exploratory-exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "The matrix weighting schemes reviewed in the first notebook for this unit deliver solid results. However, they are not capable of capturing higher-order associations in the data. \n",
    "\n",
    "With dimensionality reduction, the goal is to eliminate correlations in the input VSM and capture such higher-order notions of co-occurrence, thereby improving the overall space.\n",
    "\n",
    "As a motivating example, consider the adjectives _gnarly_ and _wicked_ used as slang positive adjectives.  Since both are positive, we expect them to be similar in a good VSM. However, at least stereotypically, _gnarly_ is Californian and _wicked_ is Bostonian. Thus, they are unlikely to occur often in the same texts, and so the methods we've reviewed so far will not be able to model their similarity. \n",
    "\n",
    "Dimensionality reduction techniques are often capable of capturing such semantic similarities (and have the added advantage of shrinking the size of our data structures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Set-up\n",
    "\n",
    "* Make sure your environment meets all the requirements for [the cs224u repository](https://github.com/cgpotts/cs224u/). For help getting set-up, see [setup.ipynb](setup.ipynb).\n",
    "\n",
    "* Make sure you've downloaded [the data distribution for this unit](http://web.stanford.edu/class/cs224u/data/vsmdata.zip), unpacked it, and placed it in the current directory (or wherever you point `data_home` to below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import copy\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PorterStemmer\n",
    "import scipy.stats\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import LinearSVC\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = 'tvtropes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = pd.read_csv(\n",
    "    os.path.join(data_home, 'dev1.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev2 = pd.read_csv(\n",
    "    os.path.join(data_home, 'dev2.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    os.path.join(data_home, 'test.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    os.path.join(data_home, 'train.balanced.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkCom\n"
     ]
    }
   ],
   "source": [
    "print(test.loc[0, 'trope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer.PorterStemmer()\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def parse_sentence(sentence):\n",
    "    s = sentence.translate(translator).split()\n",
    "    for i in range(len(s)):\n",
    "        s[i] = s[i].strip(string.punctuation).lower()\n",
    "    s = list(filter(None, s))\n",
    "    return [word for word in s if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Features\n",
    "\n",
    "Description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unigrams_phi(s):\n",
    "    return Counter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmed_phi(s):\n",
    "    return Counter([ps.stem(word) for word in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_phi(s):\n",
    "    t = copy.deepcopy(s)\n",
    "    t.insert(0, '<S>')\n",
    "    t.append('</S>')\n",
    "    bigrams = [tuple([t[i], t[i + 1]]) for i in range(len(t) - 1)]\n",
    "    return Counter(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment\n",
    "\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_X(X, phi, vectorizer=None):\n",
    "    feat_dicts = [phi(parse_sentence(sentence)) for sentence in X]\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=False)\n",
    "        return (vectorizer.fit_transform(feat_dicts), vectorizer)\n",
    "    else:\n",
    "        return (vectorizer.transform(feat_dicts), vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data, phi, vectorizer=None):\n",
    "    X = [data.loc[i, 'sentence'] for i in range(len(data.index))]\n",
    "    y = [data.loc[i, 'spoiler'] for i in range(len(data.index))]\n",
    "    feat_matrix, vectorizer = vectorize_X(X, phi, vectorizer)\n",
    "    return (normalize(feat_matrix), y, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc(X, y):\n",
    "    mod = LinearSVC()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(phi, train_func, train_data, test_data):\n",
    "    X, y, vectorizer = build_dataset(train_data, phi)\n",
    "    print(len(X[0]))\n",
    "    mod = train_func(X, y)\n",
    "    X_test, y_test, vectorizer = build_dataset(test_data, phi, vectorizer)\n",
    "    predictions = mod.predict(X_test)\n",
    "    print('Accuracy: %0.03f' % accuracy_score(y_test, predictions))\n",
    "    print(classification_report(y_test, predictions, digits=3))\n",
    "    return f1_score(y_test, predictions, average = 'macro', pos_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18968\n",
      "Accuracy: 0.614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.578     0.633     0.604       496\n",
      "       True      0.652     0.598     0.624       570\n",
      "\n",
      "avg / total      0.618     0.614     0.615      1066\n",
      "\n",
      "13520\n",
      "Accuracy: 0.618\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.584     0.623     0.603       496\n",
      "       True      0.652     0.614     0.632       570\n",
      "\n",
      "avg / total      0.620     0.618     0.619      1066\n",
      "\n",
      "110710\n",
      "Accuracy: 0.598\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.568     0.567     0.567       496\n",
      "       True      0.623     0.625     0.624       570\n",
      "\n",
      "avg / total      0.598     0.598     0.598      1066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5955589791028989"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(unigrams_phi, fit_svc, train, dev1)\n",
    "experiment(stemmed_phi, fit_svc, train, dev1)\n",
    "experiment(bigrams_phi, fit_svc, train, dev1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_phi(s):\n",
    "    t = copy.deepcopy(s)\n",
    "    is_neg = 0\n",
    "    for i in range(len(t)):\n",
    "        if is_neg > 4: is_neg = 0\n",
    "        if is_neg > 0:\n",
    "            is_neg += 1\n",
    "            t[i] = 'NOT_' + t[i]\n",
    "        if 'n\\'t' in t[i] or t[i] in ['not', 'no', 'never']: is_neg = 1\n",
    "    return Counter(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19485\n",
      "Accuracy: 0.614\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.579     0.629     0.603       496\n",
      "       True      0.651     0.602     0.625       570\n",
      "\n",
      "avg / total      0.617     0.614     0.615      1066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6141201960551175"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment(sentiment_phi, fit_svc, train, dev1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
